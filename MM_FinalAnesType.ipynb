{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code finds anesthesia types from the clinical narratives\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize, pos_tag, sent_tokenize, ToktokTokenizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from urllib import urlopen\n",
    "\n",
    "import numpy as np#for math processing ,need\n",
    "from numpy import arange #to handle ranges \n",
    "import networkx as nx # brings up node configs\n",
    "\n",
    "import unicodedata\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pandas\n",
    "import string\n",
    "import xlrd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing all relevant modules, the next few cell import the dataset from the database, and drop any potential duplicate notes in the report (which would have duplicate Note IDs). For the purpose of analyzing as much data as possible, we have now included patients with multiple reports for classification at this stage of the analysis for the sake of thoroughness (a change from how the first 130 sample post-op notes were classified with the unmodified classifier).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.shape) #check for size \n",
    "print (df.NOTE.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='NOTE_DEID') \n",
    "df = df.reset_index()\n",
    "del df['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes # see what type NOTE and NOTE CODE are in currently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are adding a space where matches in the text for anesthesia type can be recorded as a way to tabulate results, and attempt to change the type of note to string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(index=str, columns={\"NOTE\": \"NOTE\"}) # may need to add similar code for NOTE_CODE if utilizing that as well\n",
    "df['NOTE'] = df['NOTE'].astype('str') \n",
    "df[\"General\"] = np.nan\n",
    "df[\"Regional\"] = np.nan\n",
    "df[\"Local\"] = np.nan\n",
    "df = df.fillna('0')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any type of string processing, we will add the lexicon of anesthesia types and relevant terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General = [\"general\"]\n",
    "Regional = [\"regional\", \"epidural\", \"nerve\", \"block\", \"nerve block\", \"nerveblock\", \"infraclavicular\", \"axillary\", \"sciatic\", \"femoral\", \"popliteal\", \"spinal\"]\n",
    "Local = [\"local\", \"infiltration\", \"mac\"]\n",
    "#regexp = re.compile(r'|nerve|epidural|infraclavicular|axillary|sciatic nerve|femoral|popliteal|( )?\\bblock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To organize the classifier, I have moved most functions out of the for loop and into separately defined functions, as shown below;\n",
    "\n",
    "Exclude takes out all punctuation in a string, including periods, run AFTER sentences are tokenized to ensure periods are not lost. \n",
    "\n",
    "get_context pulls all information we think is relevant to anesthesia based on the format of the note. We are looking at a number of notes that have different formats and will thus have different locations for where the anesthesia information is found, according to some main rules:\n",
    "1) if the note has headers, including one for anesthesia, the classifier will pull the information between the anesthesia header and the beginning of the next header.\n",
    "2) if the note has the \"anesthesia:\" header but no other header, one of two options will happen\n",
    "    A) if there are sentences in the note, the classifier will extract the first sentence that includes the \"anesthesia:\" header.\n",
    "    B) if there are no sentences in the note, the classifier will extract the remainder of the report after the \"anesthesia:\" header.\n",
    "3) If there is no \"anesthesia\" header, but anesthesia is mentioned in the note, the classifier will extract all sentences that have anesthesia in them.\n",
    "4) if \"anesthesia\" is not mentioned at all in the note, then the classifier will extract the entire note to be processed, which is typically used when the note is an \"Anesthesia Procedure Note\".\n",
    "\n",
    "\n",
    "clean combines the above two functions into one, along with including some preprocessing functions, including lowercasing, removing digits and punctuation (to ensure sent_tokenize works correctly in the get_context function, the digits are removed before it and punctuation is removed after).\n",
    "\n",
    "classify then looks at each word in a trimmed list, and if it finds the word in the general/local/regional dictionaries, it will add a 1 to the relevant column set up earlier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(word):\n",
    "    punct = set(string.punctuation) #this requires an \"import string\" since the punctuation is stored in there. I turn it into a set for faster searches. \n",
    "    return ''.join(ch for ch in word if ch not in punct) #strips out any punctuation by testing each character to see if it's not in the set of punctuation.\n",
    "\n",
    "\n",
    "def get_context(processed_note): \n",
    "    context = []\n",
    "    #rule 1: look for headers\n",
    "    if 'anesthesia:'in processed_note:\n",
    "        after = processed_note.split('anesthesia:')[1]#WILL CUT OUT ANY information before \"anesthesia:\"\n",
    "        if \":\" in after: # checks for a second header\n",
    "            secondcolon = after.index(\":\")\n",
    "            context.append(after[:secondcolon]) # extract information between the anesthesia header and the next header\n",
    "        elif \":\" not in after: # if there is no second header\n",
    "            if \".\" in after: #if there are sentences in the note:\n",
    "                context.append(sent_tokenize(after)[0]) #extract the first sentence that includes the header\n",
    "            else:\n",
    "                context.append(after) # extract the remainder of the report right after the header\n",
    "    elif \"anesthesia\" in processed_note:#if there is no anesthesia header present\n",
    "        [context.append(sentence) for sentence in sent_tokenize(processed_note) if 'anesthesia' in sentence] # extract any sentence with anesthesia in it\n",
    "    elif \"anesthesia\" not in processed_note: # if the word anesthesia is not mentioned at all:\n",
    "        context.append(processed_note) # extract the whole report for evaluation. \n",
    "    return \" \".join(context) # output is one concentrated string\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower() #this makes all the text in the report lowercase\n",
    "    nums = set('0123456789') #for this extraction, I didn't need to look at numbers, so this is me putting all the digit characters into a set (which is really fast for finding things in).\n",
    "    text = ''.join(ch for ch in text if ch not in nums) #this takes out any digits by testing whether it's in the set I just defined. \n",
    "    text = get_context(text) #this will run it through the context extraction, to help me filter out what information would be most relevant based on the structure of the note. This is helpful for when you want to reduce the noise present in other parts of the note.\n",
    "    text1 = exclude(text) #this will strip out any punctuation, see the function a couple lines up. \n",
    "    return text1 #cleaned up text\n",
    "\n",
    "\n",
    "def classify(key): #for when input is the full string, could be slow\n",
    "    for word in Regional:\n",
    "        if word in key:\n",
    "             df.loc[index,\"Regional\"] = 1 \n",
    "    for word in General:\n",
    "        if word in key:\n",
    "             df.loc[index,\"General\"] = 1 \n",
    "    for word in Local:\n",
    "        if word in key:\n",
    "             df.loc[index,\"Local\"] = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual classification of the anesthesia.\n",
    "From the dataframe set up earlier, it will take the Note from each row, run it through the preprocessing function(s) defined earlier to extract the relevant anesthesia information, and then classify and record the results in the general/regional/local columns according to what is found in this new list as a way to tabulate the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    note = row[str(\"NOTE\")]\n",
    "    note = clean(note)\n",
    "    classify(note)\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to ensure values have been recorded correctly\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writes certain columns of dataframe to an Excel output file. \n",
    "format1 ensures the NoteDEID is preserved in its integer form instead of being written in exponential/scientific notation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "df = df[[\"PAT_DEID\",\"NOTE_DEID\", \"NOTE_CODE\", \"General\",\"Regional\",\"Local\"]]\n",
    "writer = pandas.ExcelWriter('anes_results_full.xls',engine = \"xlsxwriter\")\n",
    "df.to_excel(writer, sheet_name = 'Sheet1')\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "format1 = workbook.add_format({'num_format': '0'})\n",
    "worksheet.set_column('C:C', None, format1)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
